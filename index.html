<!DOCTYPE html>
<html lang="en-US">
  <head>

    
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Security and Safety in Machine Learning Systems | Workshop at ICLR 2021</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Security and Safety in Machine Learning Systems" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Workshop at ICLR 2021" />
<meta property="og:description" content="Workshop at ICLR 2021" />
<meta property="og:site_name" content="Security and Safety in Machine Learning Systems" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Security and Safety in Machine Learning Systems" />
<script type="application/ld+json">
{"headline":"Security and Safety in Machine Learning Systems","url":"/","name":"Security and Safety in Machine Learning Systems","description":"Workshop at ICLR 2021","@type":"WebSite","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/aml-iclr2021/assets/css/style.css?v=">
  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Security and Safety in Machine Learning Systems</h1>
      <h2 class="project-tagline">Workshop at ICLR 2021</h2>
      
      
      <a href="/aml-iclr2021" class="btn">Home</a>
      
      <a href="/aml-iclr2021/cfp" class="btn">Call for Papers</a>
      
      <a href="/aml-iclr2021/papers" class="btn">Accepted Papers</a>
      
      <a href="/aml-iclr2021/schedule" class="btn">Schedule</a>
      
      <a href="/aml-iclr2021/speakers" class="btn">Speakers</a>
      
      <a href="/aml-iclr2021/organizers" class="btn">Organizers</a>
      
      <a href="/aml-iclr2021/committee" class="btn">Program Committee</a>
      
      <a href="/aml-iclr2021/related" class="btn">Related Workshops</a>
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="overview">Overview</h1>

<table>
  <tbody>
    <tr>
      <td><strong>Date</strong></td>
      <td>May 7, 2021</td>
    </tr>
    <tr>
      <td><strong>Location</strong></td>
      <td>The workshop will be held <em>virtually</em>. The internal ICLR workshop website is <a href="https://iclr.cc/virtual/2021/workshop/2127">here</a> (ICLR registration required).</td>
    </tr>
  </tbody>
</table>

<p>While machine learning (ML) models have achieved great success in many applications, concerns have been raised about their potential vulnerabilities and risks when applied to safety-critical applications. On the one hand, from the security perspective, studies have been conducted to explore worst-case attacks against ML models and therefore inspire both empirical and certifiable defense approaches. On the other hand, from the safety perspective, researchers have looked into safe constraints, which should be satisfied by safe AI systems (e.g., autonomous driving vehicles should not hit pedestrians).</p>

<p>In this workshop, we aim to bridge the gap of these two communities and discuss principles of developing secure and safe ML systems. We will bring together experts from machine learning, computer security, and AI safety communities. We attempt to highlight recent related work from different communities, clarify the foundations of secure and safe ML, and chart out important directions for future work and cross-community collaborations.</p>

<h1 id="paper-awards">Paper Awards</h1>

<h2 id="best-paper-award">Best Paper Award</h2>

<ul>
  <li><b><a href="https://aisecure-workshop.github.io/aml-iclr2021/papers/21.pdf">Ditto: Fair and Robust Federated Learning Through Personalization</a></b> <br /> Tian Li (Carnegie Mellon University); Shengyuan Hu (Carnegie Mellon University); Ahmad Beirami (Facebook AI); Virginia Smith (Carnegie Mellon University)</li>
</ul>

<h2 id="best-paper-honorable-mention-award">Best Paper Honorable Mention Award</h2>

<ul>
  <li><b><a href="https://aisecure-workshop.github.io/aml-iclr2021/papers/47.pdf">RobustBench: a standardized adversarial robustness benchmark</a></b> <br /> Francesco Croce (University of Tübingen); Maksym Andriushchenko (EPFL); Vikash Sehwag (Princeton University); Edoardo Debenedetti (EPFL); Nicolas Flammarion (EPFL); Mung Chiang (Princeton University); Prateek Mittal (Princeton University); Matthias Hein (University of Tübingen)</li>
</ul>

<h2 id="travel-award-recipients">Travel Award Recipients</h2>

<ul>
  <li>Fartash Faghri (University of Toronto)</li>
  <li>Jay Nandy (National University of Singapore)</li>
  <li>Mingjie Sun (Carnegie Mellon University)</li>
  <li>Linxi Jiang (Fudan University)</li>
  <li>Siyue Wang (Northeastern University)</li>
  <li>Liam Fowl (University of Maryland)</li>
  <li>Seyedeh Hanieh Hashemi (University of Southern California)</li>
  <li>Sylvestre-Alvise Rebuffi (DeepMind)</li>
  <li>Ingkarat Rak-Amnouykit (Rensselaer Polytechnic Institute)</li>
  <li>Wen Shen (Tulane University)</li>
  <li>Vasu Singla (University of Maryland)</li>
  <li>Daniel Ley (University of Cambridge)</li>
  <li>Yoshihiro Okawa (Fujitsu Laboratories Ltd.)</li>
  <li>Chong Xiang (Princeton University)</li>
  <li>Kyungmin Lee (Agency for defense development)</li>
  <li>Mengdi Xu (Carnegie Mellon University)</li>
  <li>Can Bakiskan (University of California, Santa Barbara)</li>
  <li>Xiangyu Qi (Zhejiang University)</li>
  <li>Xiao Zhang (Leiden University)</li>
  <li>Guanhong Tao (Purdue University)</li>
  <li>Vikash Sehwag (Princeton University)</li>
  <li>Dequan Wang (UC Berkeley)</li>
  <li>Eitan Borgnia (University of Maryland)</li>
  <li>Jaydeep Borkar (Savitribal Phule Pune University)</li>
  <li>Mantas Mazeika (UIUC)</li>
</ul>

<p>The workshop is sponsored by <a href="https://www.openphilanthropy.org/">Open Philanthropy</a>. The funding covers a Best Paper Award ($1,000), a Best Paper Honorable Mention Award ($500), and multiple travel grants (complimentary ICLR conference registrations).</p>

<p align="center">
	<img src="./assets/images/OpenPhil.png" alt="Open Phil" width="350" />
</p>


      <footer class="site-footer">
        <span class="site-footer-credits">Please contact <a href="mailto:xinyun.chen@berkeley.edu">Xinyun Chen</a> or <a href="mailto:cihangxie306@gmail.com">Cihang Xie</a> if you have any questions.<br> The webpage template is by the courtesy of <a href="https://tda-in-ml.github.io/">NeurIPS 2020 Workshop on Topological Data Analysis and Beyond</a>. <br> 
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>
          on Tue, 06 December 2022 20:33:05.
        </span>
      </footer>
    </main>
  </body>
</html>
